{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html\n",
    "2. \"Uncertainty in deep learning\" Yarin Gal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: GeForce 820M (CNMeM is disabled, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bayesian.callbacks import ModelTest\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import Input\n",
    "from keras.layers.core import Dense, Dropout\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
    "from keras.regularizers import l2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.utils import to_categorical\n",
    "import itertools\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/oleksandr/Documents/bayesian'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([\n",
    "    [-1, -1],\n",
    "    [-0.7, -0.5],\n",
    "    [-0.5, -0.1],\n",
    "    [-0.2, 0.5], \n",
    "    [0, 0.8],\n",
    "    [0.2, 0.5],\n",
    "    [0.5, 0.2],\n",
    "    [0.7, 0.0],\n",
    "    [1, 0.3],\n",
    "    [1.2, 0.5],\n",
    "    [1.5, 0.8],\n",
    "    [3.5, 0.5],\n",
    "    [4.0, 0.35],\n",
    "    [4.5, 0.2],\n",
    "    [5.0, 0.05],\n",
    "    [5.5, -0.1]\n",
    "])\n",
    "x = xy[:, 0] *2 \n",
    "y = xy[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.array([\n",
    "    [-1, -1],\n",
    "    [-0.7, -0.5],\n",
    "    [-0.5, -0.1],\n",
    "    [-0.2, 0.5], \n",
    "    [0, 0.8],\n",
    "    [0.2, 0.5],\n",
    "    [0.5, 0.2],\n",
    "    [0.7, 0.0],\n",
    "    [1, 0.3],\n",
    "    [1.2, 0.5],\n",
    "    [1.5, 0.8],\n",
    "    [3.5, -0.5],\n",
    "    [4.0, 0.35],\n",
    "    [4.5, -0.2],\n",
    "    [5.0, 0.05],\n",
    "    [5.5, -0.5]\n",
    "])\n",
    "x = xy[:, 0] *2 \n",
    "y = xy[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.linspace(-10, 10, 300)\n",
    "# y = (1 - 2.5*np.power(x, 2)) * np.exp(-np.power(x, 2)) + np.random.normal(0, 0.05, size=len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_f(x):\n",
    "    v = np.zeros(len(x))\n",
    "    v[x < 2.5] = 0.1\n",
    "    v[x>=2.5]= x[x>2.5]*1.4\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_f(x):\n",
    "    v = np.copy(x)\n",
    "    v[v<0] = 1\n",
    "    v = np.log(v) * 0.08\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = np.concatenate([np.linspace(-10, -1.1, 100), np.linspace(1.1, 10, 100)])#, np.array([0, -0.1, 0.1])])\n",
    "#x = np.linspace(-10, 10, 200)\n",
    "x = np.random.uniform(-10, 10, 30)\n",
    "def f(x):\n",
    "    return (1 - 2.5*np.power(0.6*x, 2)) * np.exp(-np.power(0.6*x, 2))\n",
    "\n",
    "\n",
    "# def f(x):\n",
    "#     return np.exp(-np.sqrt(np.abs(x))) * np.cos(x)\n",
    "\n",
    "\n",
    "y = f(x) + np.random.normal(0, 0.1, size=len(x)) * var_f(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y, 'bo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x.reshape(-1, 1)\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dropout = 0.05\n",
    "weight_decay = 0.001\n",
    "batch_size=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #regression\n",
    "# mean_y_train = np.mean(y_train)\n",
    "# std_y_train = np.std(y_train)\n",
    "# y_train = (y_train - mean_y_train) / std_y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian.bayesian_dropout_model import BayesianDropoutModel\n",
    "from bayesian.metrics import bayesian_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# Build model:\n",
    "print('Build model...')\n",
    "\n",
    "# model.add(Dropout(p_dropout, \n",
    "#                   input_shape=(X_train.shape[1], ),\n",
    "#                  ))\n",
    "inp = Input(shape=((X_train.shape[1], )))\n",
    "layer = Dense(25,\n",
    "           activation='relu',\n",
    "           kernel_regularizer=l2(weight_decay),\n",
    "           bias_regularizer=l2(weight_decay))(inp)\n",
    "layer = Dropout(p_dropout)(layer)\n",
    "layer = Dense(25,\n",
    "                activation='sigmoid',\n",
    "                kernel_regularizer=l2(weight_decay),\n",
    "                bias_regularizer=l2(weight_decay))(layer)\n",
    "layer = Dropout(p_dropout)(layer)\n",
    "output = Dense(y_train.shape[1] if len(y_train.shape) > 1 else 1,\n",
    "                activation='linear',\n",
    "                kernel_regularizer=l2(weight_decay), bias_regularizer=l2(weight_decay))(layer)\n",
    "\n",
    "model = BayesianDropoutModel([inp], [output])\n",
    "\n",
    "optimiser = SGD(lr=0.01, decay=1e-5)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.topology.InputLayer'> (None, 1) (None, 1)\n",
      "<class 'keras.layers.core.Dense'> (None, 1) (None, 25)\n",
      "<class 'keras.layers.core.Dropout'> (None, 25) (None, 25)\n",
      "<class 'keras.layers.core.Dense'> (None, 25) (None, 25)\n",
      "<class 'keras.layers.core.Dropout'> (None, 25) (None, 25)\n",
      "<class 'keras.layers.core.Dense'> (None, 25) (None, 1)\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers:\n",
    "    print(type(l), l.input_shape, l.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Potentially load weights\n",
    "# model.load_weights(\"path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def standardize_X(X):\n",
    "#     if type(X) == list:\n",
    "#         return X\n",
    "#     else:\n",
    "#         return [X]\n",
    "import time \n",
    "class DrawCallback(Callback):\n",
    "    def __init__(self, x, y, T, fig, ax):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.T = T\n",
    "        self.ax = ax\n",
    "        self.fig = fig\n",
    "        #self.mean_y_train = mean_y_train\n",
    "        #self.std_y_train = std_y_train\n",
    "        \n",
    "        #self.y = f(x)\n",
    "    \n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        #xx = np.linspace(x.min()-0.5, x.max()+0.5, 100).reshape(-1, 1)\n",
    "        #T = 100\n",
    "        prob = np.array([self.model.predict_stochastic(self.x, batch_size=500, verbose=0)\n",
    "                         for _ in range(self.T)])\n",
    "        prob_mean = np.mean(prob, 0) #* self.std_y_train + self.mean_y_train\n",
    "        prob_std = bayesian_std(prob, l=1, p_dropout=p_dropout, weight_decay=weight_decay, N=len(X_train))\n",
    "        \n",
    "        #fig.clf()\n",
    "        ax.cla()\n",
    "        \n",
    "        #ax.plot(self.x, self.y, 'b-')\n",
    "        ax.plot(x, y, 'bo')\n",
    "        ax.plot(self.x, prob_mean, 'r--')\n",
    "        for n_std, alpha in zip([0.5, 1, 1.5], [0.3, 0.2, 0.1]):\n",
    "            ax.fill_between(self.x.ravel(),\n",
    "                     (prob_mean-n_std * prob_std).ravel(), \n",
    "                     (prob_mean+n_std * prob_std).ravel(), alpha=alpha, color='red')\n",
    "        ax.set_xlim(self.x.min()-0.5, self.x.max()+0.5)\n",
    "        ax.set_ylim(self.y.min()-0.5, self.y.max()+0.5)\n",
    "        fig.canvas.draw()\n",
    "        time.sleep(0.01)\n",
    "        #print('draw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "print(\"Train...\")\n",
    "\n",
    "plt.ion()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "draw = DrawCallback(x=np.linspace(x.min()-0.5, x.max()+0.5, 100).reshape(-1, 1), \n",
    "                   y=y_train,\n",
    "                   #mean_y_train=mean_y_train,\n",
    "                   #std_y_train=std_y_train,\n",
    "                   T=150,\n",
    "                   ax = ax,\n",
    "                   fig=fig)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=10000, \n",
    "          callbacks=[draw], verbose=0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesian.objectives import bayesian_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "# Build model:\n",
    "print('Build model...')\n",
    "\n",
    "# model.add(Dropout(p_dropout, \n",
    "#                   input_shape=(X_train.shape[1], ),\n",
    "#                  ))\n",
    "inp = Input(shape=((X_train.shape[1], )))\n",
    "layer = Dense(25,\n",
    "           activation='relu',\n",
    "           kernel_regularizer=l2(weight_decay),\n",
    "           bias_regularizer=l2(weight_decay))(inp)\n",
    "layer = Dropout(p_dropout)(layer)\n",
    "layer = Dense(25,\n",
    "                activation='relu',\n",
    "                kernel_regularizer=l2(weight_decay),\n",
    "                bias_regularizer=l2(weight_decay))(layer)\n",
    "layer = Dropout(p_dropout)(layer)\n",
    "output = Dense(1,\n",
    "                activation='linear',\n",
    "                kernel_regularizer=l2(weight_decay), bias_regularizer=l2(weight_decay))(layer)\n",
    "\n",
    "var = Dense(1, activation='linear',\n",
    "            kernel_regularizer=l2(weight_decay), bias_regularizer=l2(weight_decay))(layer)\n",
    "\n",
    "final_output = Concatenate()([output, var])\n",
    "model = BayesianDropoutModel([inp], [final_output])\n",
    "\n",
    "optimiser = 'adam'\n",
    "model.compile(loss=bayesian_mean_squared_error, optimizer=optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def standardize_X(X):\n",
    "#     if type(X) == list:\n",
    "#         return X\n",
    "#     else:\n",
    "#         return [X]\n",
    "    \n",
    "class DrawCallback2(Callback):\n",
    "    def __init__(self, x, y, T, fig, ax):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.T = T\n",
    "        self.ax = ax\n",
    "        self.fig = fig\n",
    "        #self.mean_y_train = mean_y_train\n",
    "        #self.std_y_train = std_y_train\n",
    "        \n",
    "        #self.y = f(x)\n",
    "    \n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        #xx = np.linspace(x.min()-0.5, x.max()+0.5, 100).reshape(-1, 1)\n",
    "        #T = 100\n",
    "        pred = np.array([self.model.predict_stochastic(self.x, batch_size=500, verbose=0)\n",
    "                         for _ in range(self.T)])\n",
    "        y_pred = pred[:, :, 0]\n",
    "        #print(y_pred.shape)\n",
    "        prob_mean = np.mean(y_pred, 0) #* self.std_y_train + self.mean_y_train\n",
    "        epistemic_prob_std = bayesian_std(y_pred, l=1, p_dropout=p_dropout, weight_decay=weight_decay, N=len(X_train))\n",
    "        \n",
    "        aleatoric_log_var = np.mean(pred[:, :, 1], 0)#self.model.predict(self.x)[:, 1]\n",
    "        aleatoric_var = np.exp(aleatoric_log_var)\n",
    "        aleatoric_std = np.sqrt(aleatoric_var)\n",
    "        \n",
    "        #fig.clf()\n",
    "        self.ax.cla()\n",
    "        self.ax.plot(self.x, f(self.x), 'b-')\n",
    "        self.ax.plot(x, y, 'bo')\n",
    "        self.ax.plot(self.x, prob_mean, 'r--')\n",
    "        \n",
    "        for n_std, alpha in zip([0.5, 1, 1.5], [0.3, 0.2, 0.1]):\n",
    "            self.ax.fill_between(self.x.ravel(),\n",
    "                     (prob_mean-n_std * epistemic_prob_std).ravel(), \n",
    "                     (prob_mean+n_std * epistemic_prob_std).ravel(), alpha=alpha, color='red')\n",
    "            \n",
    "            self.ax.fill_between(self.x.ravel(),\n",
    "                     (prob_mean-n_std * aleatoric_std).ravel(), \n",
    "                     (prob_mean+n_std * aleatoric_std).ravel(), alpha=alpha, color='green')\n",
    "            \n",
    "        self.ax.set_xlim(self.x.min()-0.5, self.x.max()+0.5)\n",
    "        self.ax.set_ylim(y_pred.min(), y_pred.max())\n",
    "        self.ax.set_ylim(self.y.min()-0.5, self.y.max()+0.5)\n",
    "        self.fig.canvas.draw()\n",
    "        #print('draw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Epoch 1/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1720\n",
      "Epoch 2/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3544\n",
      "Epoch 3/5000\n",
      "30/30 [==============================] - 0s - loss: -4.9925\n",
      "Epoch 4/5000\n",
      "30/30 [==============================] - 0s - loss: -3.9007\n",
      "Epoch 5/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0975\n",
      "Epoch 6/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0884\n",
      "Epoch 7/5000\n",
      "30/30 [==============================] - 0s - loss: -5.5576\n",
      "Epoch 8/5000\n",
      "30/30 [==============================] - 0s - loss: -4.8888\n",
      "Epoch 9/5000\n",
      "30/30 [==============================] - 0s - loss: -4.9065\n",
      "Epoch 10/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2974\n",
      "Epoch 11/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4380\n",
      "Epoch 12/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1050\n",
      "Epoch 13/5000\n",
      "30/30 [==============================] - 0s - loss: -4.7451\n",
      "Epoch 14/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2276\n",
      "Epoch 15/5000\n",
      "30/30 [==============================] - 0s - loss: -4.3804\n",
      "Epoch 16/5000\n",
      "30/30 [==============================] - 0s - loss: -4.9654\n",
      "Epoch 17/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3403\n",
      "Epoch 18/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0933\n",
      "Epoch 19/5000\n",
      "30/30 [==============================] - 0s - loss: -4.7756\n",
      "Epoch 20/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0468\n",
      "Epoch 21/5000\n",
      "30/30 [==============================] - 0s - loss: -5.6671\n",
      "Epoch 22/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2351\n",
      "Epoch 23/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2209\n",
      "Epoch 24/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0501\n",
      "Epoch 25/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0077\n",
      "Epoch 26/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1522\n",
      "Epoch 27/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2411\n",
      "Epoch 28/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4584\n",
      "Epoch 29/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1401\n",
      "Epoch 30/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3123\n",
      "Epoch 31/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2897\n",
      "Epoch 32/5000\n",
      "30/30 [==============================] - 0s - loss: -5.6814\n",
      "Epoch 33/5000\n",
      "30/30 [==============================] - 0s - loss: -4.9015\n",
      "Epoch 34/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1967\n",
      "Epoch 35/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2793\n",
      "Epoch 36/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0881\n",
      "Epoch 37/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0169\n",
      "Epoch 38/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2131\n",
      "Epoch 39/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2768\n",
      "Epoch 40/5000\n",
      "30/30 [==============================] - 0s - loss: -4.9335\n",
      "Epoch 41/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1666\n",
      "Epoch 42/5000\n",
      "30/30 [==============================] - 0s - loss: -5.7231\n",
      "Epoch 43/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0001\n",
      "Epoch 44/5000\n",
      "30/30 [==============================] - 0s - loss: -5.6015\n",
      "Epoch 45/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0776\n",
      "Epoch 46/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2727\n",
      "Epoch 47/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2868\n",
      "Epoch 48/5000\n",
      "30/30 [==============================] - 0s - loss: -4.8626\n",
      "Epoch 49/5000\n",
      "30/30 [==============================] - 0s - loss: -4.4953\n",
      "Epoch 50/5000\n",
      "30/30 [==============================] - 0s - loss: -4.8570\n",
      "Epoch 51/5000\n",
      "30/30 [==============================] - 0s - loss: -4.4730\n",
      "Epoch 52/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0953\n",
      "Epoch 53/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2559\n",
      "Epoch 54/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2878\n",
      "Epoch 55/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0389\n",
      "Epoch 56/5000\n",
      "30/30 [==============================] - 0s - loss: -4.8420\n",
      "Epoch 57/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3297\n",
      "Epoch 58/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2376\n",
      "Epoch 59/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0159\n",
      "Epoch 60/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0022\n",
      "Epoch 61/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3343\n",
      "Epoch 62/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0019\n",
      "Epoch 63/5000\n",
      "30/30 [==============================] - 0s - loss: -4.9488\n",
      "Epoch 64/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0204\n",
      "Epoch 65/5000\n",
      "30/30 [==============================] - 0s - loss: -5.5693\n",
      "Epoch 66/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2653\n",
      "Epoch 67/5000\n",
      "30/30 [==============================] - 0s - loss: -4.8700\n",
      "Epoch 68/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3830\n",
      "Epoch 69/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0662\n",
      "Epoch 70/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4080\n",
      "Epoch 71/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2125\n",
      "Epoch 72/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3874\n",
      "Epoch 73/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2329\n",
      "Epoch 74/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4312\n",
      "Epoch 75/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3186\n",
      "Epoch 76/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4278\n",
      "Epoch 77/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1338\n",
      "Epoch 78/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1000\n",
      "Epoch 79/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1350\n",
      "Epoch 80/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0956\n",
      "Epoch 81/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4780\n",
      "Epoch 82/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1973\n",
      "Epoch 83/5000\n",
      "30/30 [==============================] - 0s - loss: -5.6034\n",
      "Epoch 84/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4735\n",
      "Epoch 85/5000\n",
      "30/30 [==============================] - 0s - loss: -4.8291\n",
      "Epoch 86/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0759\n",
      "Epoch 87/5000\n",
      "30/30 [==============================] - 0s - loss: -4.9883\n",
      "Epoch 88/5000\n",
      "30/30 [==============================] - 0s - loss: -5.6357\n",
      "Epoch 89/5000\n",
      "30/30 [==============================] - 0s - loss: -4.6619\n",
      "Epoch 90/5000\n",
      "30/30 [==============================] - 0s - loss: -3.5176\n",
      "Epoch 91/5000\n",
      "30/30 [==============================] - 0s - loss: -4.8722\n",
      "Epoch 92/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0721\n",
      "Epoch 93/5000\n",
      "30/30 [==============================] - 0s - loss: -4.8793\n",
      "Epoch 94/5000\n",
      "30/30 [==============================] - 0s - loss: -4.9765\n",
      "Epoch 95/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3102\n",
      "Epoch 96/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4259\n",
      "Epoch 97/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1327\n",
      "Epoch 98/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0575\n",
      "Epoch 99/5000\n",
      "30/30 [==============================] - 0s - loss: -4.7360\n",
      "Epoch 100/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4202\n",
      "Epoch 101/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3001\n",
      "Epoch 102/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0544\n",
      "Epoch 103/5000\n",
      "30/30 [==============================] - 0s - loss: -4.9276\n",
      "Epoch 104/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4524\n",
      "Epoch 105/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2315\n",
      "Epoch 106/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2662\n",
      "Epoch 107/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4906\n",
      "Epoch 108/5000\n",
      "30/30 [==============================] - 0s - loss: -5.5676\n",
      "Epoch 109/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1872\n",
      "Epoch 110/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1240\n",
      "Epoch 111/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s - loss: -5.4766\n",
      "Epoch 112/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2534\n",
      "Epoch 113/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2401\n",
      "Epoch 114/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2969\n",
      "Epoch 115/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3542\n",
      "Epoch 116/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3054\n",
      "Epoch 117/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2988\n",
      "Epoch 118/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2199\n",
      "Epoch 119/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4400\n",
      "Epoch 120/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1775\n",
      "Epoch 121/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1955\n",
      "Epoch 122/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2029\n",
      "Epoch 123/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0430\n",
      "Epoch 124/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0527\n",
      "Epoch 125/5000\n",
      "30/30 [==============================] - 0s - loss: -5.5605\n",
      "Epoch 126/5000\n",
      "30/30 [==============================] - 0s - loss: -5.0816\n",
      "Epoch 127/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1190\n",
      "Epoch 128/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1027\n",
      "Epoch 129/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4639\n",
      "Epoch 130/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3382\n",
      "Epoch 131/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4565\n",
      "Epoch 132/5000\n",
      "30/30 [==============================] - 0s - loss: -4.9601\n",
      "Epoch 133/5000\n",
      "30/30 [==============================] - 0s - loss: -5.5272\n",
      "Epoch 134/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1067\n",
      "Epoch 135/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3233\n",
      "Epoch 136/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4896\n",
      "Epoch 137/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2864\n",
      "Epoch 138/5000\n",
      "30/30 [==============================] - 0s - loss: -5.5579\n",
      "Epoch 139/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4752\n",
      "Epoch 140/5000\n",
      "30/30 [==============================] - 0s - loss: -4.8770\n",
      "Epoch 141/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1540\n",
      "Epoch 142/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2515\n",
      "Epoch 143/5000\n",
      "30/30 [==============================] - 0s - loss: -4.8026\n",
      "Epoch 144/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3350\n",
      "Epoch 145/5000\n",
      "30/30 [==============================] - 0s - loss: -5.4978\n",
      "Epoch 146/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2370\n",
      "Epoch 147/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3830\n",
      "Epoch 148/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3405\n",
      "Epoch 149/5000\n",
      "30/30 [==============================] - 0s - loss: -5.7475\n",
      "Epoch 150/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1476\n",
      "Epoch 151/5000\n",
      "30/30 [==============================] - 0s - loss: -5.6289\n",
      "Epoch 152/5000\n",
      "30/30 [==============================] - 0s - loss: -5.1864\n",
      "Epoch 153/5000\n",
      "30/30 [==============================] - 0s - loss: -4.9090\n",
      "Epoch 154/5000\n",
      "30/30 [==============================] - 0s - loss: -5.3642\n",
      "Epoch 155/5000\n",
      "30/30 [==============================] - 0s - loss: -5.2272\n",
      "Epoch 156/5000\n",
      "30/30 [==============================] - 0s - loss: -4.6188\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c731366e8769>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m model.fit(X_train, y_train, batch_size=batch_size, epochs=5000, \n\u001b[0;32m---> 18\u001b[0;31m           callbacks=[draw], verbose=1)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 \u001b[0mindex_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_batch_shuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts_batch_begin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-ac3bab0ad006>\u001b[0m in \u001b[0;36mon_epoch_begin\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#T = 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         pred = np.array([self.model.predict_stochastic(self.x, batch_size=500, verbose=0)\n\u001b[0;32m---> 24\u001b[0;31m                          for _ in range(self.T)])\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#print(y_pred.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-ac3bab0ad006>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#T = 100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         pred = np.array([self.model.predict_stochastic(self.x, batch_size=500, verbose=0)\n\u001b[0;32m---> 24\u001b[0;31m                          for _ in range(self.T)])\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#print(y_pred.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/bayesian/bayesian/bayesian_dropout_model.py\u001b[0m in \u001b[0;36mpredict_stochastic\u001b[0;34m(self, X, batch_size, verbose)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'theano'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             result = self._predict_loop(self._predict_stochastic, X, batch_size=batch_size,\n\u001b[0;32m---> 70\u001b[0;31m                                         verbose=verbose)\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unknown backend'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1210\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Train...\")\n",
    "\n",
    "plt.ion()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "\n",
    "draw = DrawCallback2(x=np.linspace(x.min()-0.5, x.max()+0.5, 200).reshape(-1, 1), \n",
    "                   y=y_train,\n",
    "                   #mean_y_train=mean_y_train,\n",
    "                   #std_y_train=std_y_train,\n",
    "                   T=50,\n",
    "                   ax = ax,\n",
    "                   fig=fig)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=5000, \n",
    "          callbacks=[draw], verbose=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ion()\n",
    "fig, ax = plt.subplots()\n",
    "draw = DrawCallback2(x=np.linspace(x.min()-0.5, x.max()+100.5, 200).reshape(-1, 1), \n",
    "                   y=y_train,\n",
    "                   T=50,\n",
    "                   ax = ax,\n",
    "                   fig=fig)\n",
    "draw.model = model\n",
    "draw.on_epoch_begin(epoch=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.linspace(X_train.min()-0.5, X_train.max()+0.5, 100).reshape(-1, 1)\n",
    "pred = np.array([model.predict_stochastic(xx, batch_size=500, verbose=0)\n",
    "                         for _ in range(50)])\n",
    "aleatoric_log_var = np.mean(pred[:, :, 1], 0)#self.model.predict(self.x)[:, 1]\n",
    "aleatoric_var = np.exp(aleatoric_log_var)\n",
    "aleatoric_std = np.sqrt(aleatoric_var)\n",
    "\n",
    "aleatoric_std_2 = np.sqrt(np.exp(model.predict(xx)[:, 1]))\n",
    "\n",
    "plt.plot(xx, aleatoric_std, 'ro', label='predicted MC uncertainty')\n",
    "plt.plot(xx, aleatoric_std_2, 'bo', label='predicted uncertainty')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
